{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Aprendizaje con Clases Desbalanceadas\n",
    "\n",
    "En el aprendizaje supervisado se considera que un conjunto de entrenamiento de dos clases está desbalanceado cuando el número de muestras de una de las clases (la clase mayoritaria) sobrepasa el número de muestras de la otra (la clase minoritaria).\n",
    "\n",
    "En este Notebook se busca evidenciar como los clasificadores pueden estar sesgados cuando se entrenan con un conjunto de datos desbalanceados. Adicionalmente, usaremos algunos de los métodos de muestreo para abordar este problema y veremos cuál es su impacto en la distribución de las clases y en la construcción de las fronteras de decisión de un clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciamos importando las librerías básicas a utilizar\n",
    "%matplotlib inline\n",
    "import numpy as np    #Biblioteca para el manejo de arreglos y matrices en Python\n",
    "import seaborn as sns #Biblioteca para la visualización de conjunto de datos de tipo DataFrame\n",
    "import pandas as pd   #Biblioteca para la manipulación de conjuntos de datos, en nuestro caso DataFrames\n",
    "import imblearn       #Biblioteca para balanceo de clases\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt    #Clase para la genearación de gráficos\n",
    "from sklearn.datasets import make_blobs #Clase para crear conjuntos de datos basados en Gaussianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evidenciando el problema\n",
    "\n",
    "Para evidenciar el problema, vamos a crear dos conjuntos de datos de juguete (toy dataset) a partir de dos Gaussianas en 2D (una por clase). En el conjunto de datos desbalaceado (X_des), la primera clase tiene 100 instancias y la segunda 900; es decir, el conjunto está desbalanceado y la clase minoritaria tiene una proporción de 1/10, respecto al conjunto de datos completo. El otro conjunto (X_blc) está balaceado y tiene 1000 instancias en cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos dos Gaussianas - Una con centro (0,0) y otra con centro (3,3)\n",
    "X_des, y_des = make_blobs(n_samples=[100, 900], centers=[(0, 0), (3, 3)], n_features=[2, 2], random_state=0)\n",
    "X_blc, y_blc = make_blobs(n_samples=[1000, 1000], centers=[(0, 0), (3, 3)], n_features=[2, 2], random_state=0)\n",
    "\n",
    "# Craemos un DataFrame a partir de los datos para visualizarlos rápidamente con seaborn\n",
    "df_des = pd.DataFrame(data=X_des, columns=[\"x1\", \"x2\"])\n",
    "df_des['y'] = y_des\n",
    "\n",
    "df_blc = pd.DataFrame(data=X_blc, columns=[\"x1\", \"x2\"])\n",
    "df_blc['y'] = y_blc\n",
    "\n",
    "#Creamos un subplot para visualizar y comparar los conjuntos de datos\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "#Visualizamos el conjunto de datos balanceado\n",
    "sns.scatterplot(data=df_blc, x=\"x1\", y=\"x2\", hue=\"y\", style=\"y\", palette=\"tab10\", ax=ax1)\n",
    "sns.scatterplot(data=df_des, x=\"x1\", y=\"x2\", hue=\"y\", style=\"y\", palette=\"tab10\", ax=ax2)\n",
    "ax1.set_title('Conjuntos de datos Balanceado')\n",
    "ax2.set_title('Conjuntos de datos Desbalanceado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenemos una SVM lineal con los dos conjuntos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#SVM lineal con el conjunto de datos balanceado\n",
    "clc_blc = LinearSVC()\n",
    "clc_blc.fit(X_blc, y_blc)\n",
    "\n",
    "#SVM lineal con el conjunto de datos desbalanceado\n",
    "clc_des = LinearSVC()\n",
    "clc_des.fit(X_des, y_des)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Esta función la usaremos para mostrar las fronteras de decisión de los clasificadores entrenados\n",
    "###\n",
    "\n",
    "def plot_decision_function(X, y, clf, ax):\n",
    "    cmap=\"jet\"\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "    \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.2, cmap=cmap)  \n",
    "    m = ['o', 's', 'v', '^', '<', '>', '8', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X']\n",
    "    l = np.unique(y)\n",
    "    rgb = matplotlib.cm.get_cmap(cmap)(np.linspace(0.0, 1.0, l.shape[0]))\n",
    "\n",
    "    for l in np.unique(y):\n",
    "        if (np.unique(y).shape[0] == 3 and l == 1):\n",
    "            ax.scatter(X[y==l, 0], X[y==l, 1], alpha=0.6, c=[0.17,0.62,0.17], edgecolor=[0.17,0.62,0.17], cmap=cmap, marker=m[l])\n",
    "        else:\n",
    "            ax.scatter(X[y==l, 0], X[y==l, 1], alpha=0.6, c=rgb[l], edgecolor=rgb[l], cmap=cmap, marker=m[l])\n",
    "    #ax.scatter(X[:, 0], X[:, 1], alpha=0.5, c=y, edgecolor=\"k\", cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora visualicemos las fronteras de decisión de ambos clasificadores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos las fronteras de decisión de ambos clasificadores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "plot_decision_function(X_blc, y_blc, clc_blc, ax1)\n",
    "ax1.set_title('Función de decisión con el dataset balanceado')\n",
    "\n",
    "plot_decision_function(X_des, y_des, clc_des, ax2)\n",
    "ax2.set_title('unción de decisión con el dataset balanceado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se observa cuidadosamente, vemos que el clasificador de la derecha (el entrenado con el conjunto de datos desbalanceado) empuja la frontera de decisión hacia la clase mayoritaria, lo que evidencia el sesgo del mismo por el desbalace de las clases, comparado con el clasificador que se ha entrenado con el conjunto balanceado (el de la izquierda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Técnicas de Muestreo Aleatorio\n",
    "\n",
    "Estas técnicas modifican la distribución de las clases con el fin de disminuir el grado de desbalace que hay entre las clases. Para ver el resultado de estas técnicas vamos a trabajar con un conjunto de datos diferente en el que hay 3 clases con 3 formas diferentes y  outliers incluídas en la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos el conjunto de datos de 3 clases.\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.1, 0.9],\n",
    "                           class_sep=1, random_state=34)\n",
    "\n",
    "#Creamos un DataFrame a partir del conjunto de datos, para visualizarlo\n",
    "df = pd.DataFrame(data=X, columns=[\"x1\", \"x2\"])\n",
    "df['y'] = y\n",
    "\n",
    "#Visualizamos el conjunto de datos y la distrubución de los mismos en cada eje\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"tab10\", style=\"y\", ax=ax1)\n",
    "ax1.set_title('Conjunto de datos desbalanceado con 3 clases')\n",
    "\n",
    "sns.stripplot(x=\"y\", y=\"x1\", data=df, palette=\"tab10\", ax=ax2)\n",
    "ax2.set_title('Distribución de los datos en X1')\n",
    "\n",
    "sns.stripplot(x=\"y\", y=\"x2\", data=df, palette=\"tab10\", ax=ax3)\n",
    "ax3.set_title('Distribución de los datos en X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SubMuestreo Aleatorio\n",
    "\n",
    "En el submuestreo aleatorio se seleccionan de manera aleatoria, tantas instancias de la clase mayoritaria como tenga la clase minoritaria. Esto hace que el cojunto de datos se reduzca, con base en el tamaño de la clase con menos datos. Usemos la biblioteca imblearn para aplicar este método de muestreo y veamos como cambia el número de muestras y la distribución de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#El método para realizar la selección aleatoria es RUS - RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "#Imprimimos el núemro de instancias en cada clase\n",
    "print (\"Conjunto Original:\\n\\tClase 0: \",np.sum(y==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y==1))\n",
    "print (\"\\nConjunto Modificado:\\n\\tClase 0: \",np.sum(y_rus==0), \n",
    "                           \"\\n\\tClase 1: \",np.sum(y_rus==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame a partir del conjunto de datos, para visualizarlo\n",
    "df_rus = pd.DataFrame(data=X_rus, columns=[\"x1\", \"x2\"])\n",
    "df_rus['y'] = y_rus\n",
    "\n",
    "\n",
    "#Visualizamos ambos conjuntos de datos, el original y el balanceado\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", style=\"y\", palette=\"tab10\", ax=ax1)\n",
    "ax1.set_title('Conjunto de datos original con 3 clases')\n",
    "\n",
    "sns.scatterplot(data=df_rus, x=\"x1\", y=\"x2\", hue=\"y\", style=\"y\", palette=\"tab10\", ax=ax2)\n",
    "ax2.set_title('Conjunto de datos balanceado con RUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entremos un clasificador con ambos conjuntos de datos y veamos la diferencia entre las fronteras de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se entrenan los clasificadores con los dos conjuntos de datos\n",
    "clc0 = LinearSVC()\n",
    "clc1 = LinearSVC()\n",
    "\n",
    "clc0.fit(X,y)\n",
    "clc1.fit(X_rus,y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos las fronteras de decisión de ambos clasificadores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con el conjunto original')\n",
    "\n",
    "plot_decision_function(X_rus, y_rus, clc1, ax2)\n",
    "ax2.set_title('Función de decisión con el SubMuestreo Aleatorio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SobreMuestreo Aleatorio\n",
    "\n",
    "En el sobremuestreo aleatorio las instancias de la clase minoritaria se replican de manera aleatoria hasta alcanzar el número de instancas de la clase mayoritaria. Esto hace que el cojunto de datos aumente su tamaño. Usemos la biblioteca imblearn para aplicar este método de muestreo y veamos como cambia el número de instancias y la distribución de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#El método para realizar la selección aleatoria es ROS - RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame a partir del conjunto de datos, para visualizarlo\n",
    "df_ros = pd.DataFrame(data=X_ros, columns=[\"x1\", \"x2\"])\n",
    "df_ros['y'] = y_ros\n",
    "\n",
    "#Visualizamos ambos conjuntos de datos, el original y el balanceado\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", style=\"y\", palette=\"tab10\", ax=ax1)\n",
    "ax1.set_title('Conjunto de datos original con 3 clases')\n",
    "\n",
    "sns.scatterplot(data=df_ros, x=\"x1\", y=\"x2\", hue=\"y\", style=\"y\", palette=\"tab10\", ax=ax2)\n",
    "ax2.set_title('Conjunto de datos balanceado con ROS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué nota de particular en ambos conjuntos de datos? Veámos cuántas instancias hay en cada clase en conjunto balanceado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos el núemro de instancias en cada clase\n",
    "print (\"Conjunto Original:\\n\\tClase 0: \",np.sum(y==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y==1), \n",
    "                          \"\\n\\tClase 2: \",np.sum(y==2))\n",
    "print (\"Conjunto Modificado:\\n\\tClase 0: \",np.sum(y_ros==0), \n",
    "                           \"\\n\\tClase 1: \",np.sum(y_ros==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenemos un clasificador y veámos como cambian las fronteras de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno el clasificador con el conjunto balanceado\n",
    "clc1.fit(X_ros,y_ros)\n",
    "\n",
    "#Visualizamos las fronteras de decisión de ambos clasificadores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con el conjunto original')\n",
    "\n",
    "plot_decision_function(X_ros, y_ros, clc1, ax2)\n",
    "ax2.set_title('Función de decisión con el SobreMuestreo Aleatorio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Técnicas de Muestreo Informado\n",
    "\n",
    "Este tipo de tecnicas buscan equilibrar el número de instancias en las clases, eliminando instancias retiradas de la frontera de decisión o instancias en la frontera de decisión que dfificulan al algoritmo de clasificación establece una separación adecuada de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Técnicas de SubMuestreo Informado\n",
    "\n",
    "### 3.1.1 CNN - Condensed Nearest Neighbour\n",
    "\n",
    "Este algoritmo utiliza el clasificador kNN (con k=1) para decidir, iterativamente, si una instancia debe mantenerse en el conjunto de datos o no. Su problema es que es sensible al ruido puesto que preservar las instancias ruidosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "cnn = CondensedNearestNeighbour()\n",
    "X_cnn, y_cnn = cnn.fit_resample(X, y)\n",
    "\n",
    "print (\"Conjunto con CNN:\\n\\tClase 0: \",np.sum(y_cnn==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y_cnn==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Tomek Links\n",
    "\n",
    "Tomek Links establece enlaces entre pares de instancias muy cercanas, pero de clases opuestas. El algoritmo elimina las instancias de la clase mayoritaria en el enlace lo que conlleva a que se aumente el espacio que separa las dos clases, lo que a su vez facilita el proceso de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks   \n",
    "tl = TomekLinks()\n",
    "X_tl, y_tl = tl.fit_resample(X, y)\n",
    "\n",
    "print (\"Conjunto con TL:\\n\\tClase 0: \",np.sum(y_tl==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y_tl==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 OSS - One Sided Selection \n",
    "\n",
    "Este algoritmo es una composición entre CNN y TomekLinks para eliminar las instancias consideradas ruidosas en la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection   \n",
    "oss = OneSidedSelection()\n",
    "X_oss, y_oss = oss.fit_resample(X, y)\n",
    "\n",
    "print (\"Conjunto con OSS:\\n\\tClase 0: \",np.sum(y_oss==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y_oss==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usemos los datos balanceados para entrenar diferentes clasificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clasificador entrenado con los datos obtenidos de CNN\n",
    "clc1 = LinearSVC()\n",
    "clc1.fit(X_cnn, y_cnn)\n",
    "\n",
    "#Clasificador entrenado con los datos obtenidos de Tomek Links\n",
    "clc2 = LinearSVC()\n",
    "clc2.fit(X_tl, y_tl)\n",
    "\n",
    "#Clasificador entrenado con los datos obtenidos de OSS\n",
    "clc3 = LinearSVC()\n",
    "clc3.fit(X_oss, y_oss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizemos esos clasificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con el conjunto original')\n",
    "\n",
    "plot_decision_function(X_cnn, y_cnn, clc1, ax2)\n",
    "ax2.set_title('Función de decisión con SubMuestreo CNN')\n",
    "\n",
    "fig, (ax3, ax4) = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "plot_decision_function(X_tl, y_tl, clc2, ax3)\n",
    "ax3.set_title('Función de decisión con SubMuestreo TomekLinks')\n",
    "\n",
    "plot_decision_function(X_oss, y_oss, clc3, ax4)\n",
    "ax4.set_title('Función de decisión con SubMuestreo OSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Instance Hardness Threshold\n",
    "\n",
    "Este método utiliza la predicción de un clasificador basado en probabilidades para eliminar, de la clase mayoritaria aquellas instancias que se clasifican con una probabilidad baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iht = InstanceHardnessThreshold(random_state=0, estimator=LogisticRegression(solver='lbfgs'))\n",
    "X_iht, y_iht = iht.fit_resample(X, y)\n",
    "\n",
    "print (\"Conjunto con IHT:\\n\\tClase 0: \",np.sum(y_iht==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y_iht==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clc4 = LinearSVC()\n",
    "clc4.fit(X_iht, y_iht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con  el conjunto origial')\n",
    "\n",
    "plot_decision_function(X_iht, y_iht, clc4, ax2)\n",
    "ax2.set_title('Función de decisión con SubMuestreo con IHT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Técnicas de SobreMuestreo Informado\n",
    "\n",
    "El principio de estas técnicas es aumentar el número de instancias en la clase minoritaria creando instancias artificiales que ayuden a definir mejor la frontera de decisión entre las dos clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 SMOTE\n",
    "\n",
    "A diferencia del sobremuestre aleatorio que repite las mismas muestras una y otra vez hasta alcanzar el número de instancias de la clase mayoritaria, SMOTE utiliza una heurística muy sencilla: crea instancias sintéticas en un punto aleatorio entre la línea recta que une a dos puntos de la misma clase en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "print (\"Conjunto con IHT:\\n\\tClase 0: \",np.sum(y_smote==0), \n",
    "                          \"\\n\\tClase 1: \",np.sum(y_smote==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenemos un clasificador\n",
    "clc1.fit(X_smote, y_smote)\n",
    "\n",
    "#Garfiquemos las fronteras de decisión\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con  el conjunto origial')\n",
    "\n",
    "plot_decision_function(X_smote, y_smote, clc1, ax2)\n",
    "ax2.set_title('Función de decisión con SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 ADASYN\n",
    "\n",
    "Es una variante de SMOTE que trata de identificar cuáles son los puntos de la clase minoritaria que tienen problemas en clasificarse como tal, usando un clasificador kNN. Una vez identificados esos puntos, se utiliza SMOTE ara crear las instancias sintéticas, pero usando como base los puntos identificados como difíciles de clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=0)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenemos un clasificador\n",
    "clc2.fit(X_adasyn, y_adasyn)\n",
    "\n",
    "#Garfiquemos las fronteras de decisión\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con  el conjunto origial')\n",
    "\n",
    "plot_decision_function(X_adasyn, y_adasyn, clc2, ax2)\n",
    "ax2.set_title('Función de decisión con ADASYN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 BoderlineSMOTE\n",
    "\n",
    "Esta es otra variante de SMOTE la cual trata de identificar los puntos de la clase minoritaria que están en la frontera de decisión para crear las instancias sintéticas a partir de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "border = BorderlineSMOTE(random_state=0)\n",
    "X_border, y_border = border.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenemos un clasificador\n",
    "clc3.fit(X_border, y_border)\n",
    "\n",
    "#Garfiquemos las fronteras de decisión\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con  el conjunto origial')\n",
    "\n",
    "plot_decision_function(X_border, y_border, clc3, ax2)\n",
    "ax2.set_title('Función de decisión con ADASYN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Métodos Basados en Ensambles\n",
    "\n",
    "Como se mostró, los métodos de submuestreo implican eliminar instancias de la clase mayoritaria y en ese proceso se pueden perder instancias importantes para definir la frontera de decisión de esa clase. Una alternativa a los métodos de submuestreo es el uso de métodos basados en ensambles de clasificadores los cuales pueden entrenar diferentes clasificadores con distintas muestras de la clase mayoritaria y definir, por consenso, la clase de un nuevo dato a clasificar.\n",
    "\n",
    "Veamos algunos de estos métodos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Easy Ensamble\n",
    "\n",
    "Crea subconjuntos  de datos aleatorios de la clase mayoritaria que tengan el tamaño de la clase minoritaria. Con cada subconjunto entrene un clasificador y combine sus salidas usando voto mayoritario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "eec = EasyEnsembleClassifier(random_state=42)\n",
    "eec.fit(X, y) # doctest: +ELLIPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garfiquemos las fronteras de decisión\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "plot_decision_function(X, y, clc0, ax1)\n",
    "ax1.set_title('Función de decisión con  el conjunto origial')\n",
    "\n",
    "plot_decision_function(X, y, eec, ax2)\n",
    "ax2.set_title('Función de decisión con EasyEnsamble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Versiones para aprendizaje balanceado de algoritmos basados en ensambles\n",
    "\n",
    "Se ha demostrado que los clasificadores basados en esambles mejoran el desempeño en comparación con un clasificador único. Sin embargo, se debe tener presente que estos también se ven afectados por el desbalance entre las clases. \n",
    "\n",
    "Veamos como cambia el rendimiento de un clasificador basado en esambles, comparado con versión para clases desbalanceadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Cargamos un conjunto de datos SatImage de UCI que esté entre los cnjuntos de datos de imblearn\n",
    "satimage = fetch_datasets()['satimage']\n",
    "X, y = satimage.data, satimage.target\n",
    "\n",
    "#Particionamos el conjunto de datos en partes: training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "#Exploramos como está compuesto el conjunto de datos, por lo que creamos un DataFrame\n",
    "df = pd.DataFrame(X_train)\n",
    "df['y'] = y_train\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciemos entrenando un clasificador tradicional: un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Entrenamos un árbol  de decisión\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#Evaluamos con el conjunto de test\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "#Mostramos la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión: \\n\", cm)\n",
    "print(\"\\n\\nReporte de clasificación: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en lugar de usar un solo árbol de desición usemos un ensamble de árboles entrenados con una estrategia de Bagging. Vamos a usar dos versiones: una  es el Bagging tradicional y otra es el Bagging para conjuntos desbalanceados, el cual hace un sub-muestreo aleatorio de la clase mayoritaria para balancear cada clasificador del Bagging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(n_estimators=20, random_state=0, n_jobs=-1)\n",
    "balanced_bagging = BalancedBaggingClassifier(n_estimators=20, random_state=0, n_jobs=-1)\n",
    "\n",
    "bagging.fit(X_train, y_train)\n",
    "balanced_bagging.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bg = bagging.predict(X_test)\n",
    "y_pred_bbg = balanced_bagging.predict(X_test)\n",
    "\n",
    "#Mostramos la matriz de confusión\n",
    "print(\"Matriz de Confusión de la Estrategia de Bagging: \\n\", confusion_matrix(y_test, y_pred_bg))\n",
    "print(\"\\n\\nMatriz de Confusión de la Estrategia de Bagging Balanceado: \\n\", confusion_matrix(y_test, y_pred_bbg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos la misma prueba con los ensambles basados en Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_boost = AdaBoostClassifier(n_estimators=20)\n",
    "\n",
    "eec = EasyEnsembleClassifier(n_estimators=20,\n",
    "                             base_estimator=DecisionTreeClassifier(),\n",
    "                             n_jobs=-1)\n",
    "\n",
    "ada_boost.fit(X_train, y_train)\n",
    "eec.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ada = ada_boost.predict(X_test)\n",
    "y_pred_eec = eec.predict(X_test)\n",
    "\n",
    "#Mostramos la matriz de confusión\n",
    "print(\"Matriz de Confusión de AdaBoost: \\n\", confusion_matrix(y_test, y_pred_ada))\n",
    "print(\"\\n\\nMatriz de Confusión de EasyEnsamble: \\n\", confusion_matrix(y_test, y_pred_eec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Un Ejercicio Práctico\n",
    "\n",
    "Ahora que ya conoces el problema que implica entrenar un clasificador con un conjunto de datos desbalanceado y algunas formas para abordar este problema, pues es hora de que pongas en práctica estos conocimientos con un conjunto de la vida real.\n",
    "\n",
    "La idea es trabajar sobre uno de los conjuntos de datos de una de las competencias de kaggel: Porto Seguros. Esta es la descripción del problema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nada arruina más rápido la emoción de comprar un auto nuevo que ver la factura del seguro todo riesgo del mismo. Esto es aún más doloroso cuando sabes que eres un buen conductor. No nos parece justo que tengamos que pagar tanto si siempre hemos sido conductores cautelosos durante años.\n",
    "\n",
    "Porto Seguro, una de las mayores aseguradoras de automóviles y viviendas de Brasil, está completamente de acuerdo con esto. Las imprecisiones en las predicciones de reclamaciones de las compañías de seguros de automóviles aumentan el costo del seguro para los buenos conductores y reducen el precio para los malos.\n",
    "\n",
    "Así que ahora tu tienes el desafío de entrenar un modelo que prediga la probabilidad de que un conductor haga uso de  su seguro de automóvil en el próximo año. \n",
    "\n",
    "Este conjunto de datos tiene 58 características y está divido en dos partes: una para entrenar y otra para hacer la validación de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementos a desarrollar:\n",
    "\n",
    "- Cargue los conjuntos de datos como conjuntos de datos de pandas (DataFrames)\n",
    "- Determine cuál es el grado de desbalance entre las clases\n",
    "- Entrene un modelo de clasificación (ojalá uno medianamente robusto) y calcule la precisión (accuracy) del modelo sobre el conjunto de prueba. ¿Solo con base en esta métrica, puede considerarse que el modelo es bueno?\n",
    "- Calcule y muestre la matriz de confusión. ¿Sigue pensando que el modelo anterior es bueno?\n",
    "- Utilice los métodos de muestreo aleatorio y vuelva entrenar el modelo seleccionado y evalúe las matrices de confusión. ¿Cuál es su percepción? ¿Mejoró el desempeño del modelo con alguna de estas estrategias?\n",
    "- Entre los métodos de submuestreo informado, use Condensed Nearest Neighbour e Instance Hardness Threshold. Calcule las matrices de confusión y analice si hay una mejora en el desempeño de los modelos.\n",
    "- Entre los métodos de sobremuestreo informado, use SMOTE y BorderlineSMOTE. Calcule las matrices de confusión y analice si hay una mejora en el desempeño de los modelos.\n",
    "- Entrene un clasificador RandomForest (de sklearn) y compare el resultado con la versión balanceada de ese modelo en imblearn. ¿Hay alguna mejora en los modelos?\n",
    "- Finalmente, ¿cuál es su conclusión sobre el ejercicio?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
